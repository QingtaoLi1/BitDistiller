description: Simple Amulet job on Singularity

target:
  service: sing
  name: whitney08
  workspace_name: dca-singularity

environment:
  image: amlt-sing/acpt-rocm6.1_ubuntu20.04_py3.9_pytorch2.1.2
  setup:
    - pwd
    - sudo apt-get update
    - sudo apt-get install -y vim
    # - sudo apt-get install apt-utils
    # - sudo apt-get install -y rocm-dkms hsa-rocr-asan
    - python -m venv mybd
    - source mybd/bin/activate
    - ls -l
    - python -m pip install --upgrade pip setuptools
    - python -m pip install packaging wheel ninja
    - python -m pip install --upgrade packaging wheel ninja

    # bitsandbytes HIP bug
    # - line=major, minor = map(int, torch.version.cuda.split("."))
    # - pip install --force-reinstall 'https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.45.3.dev272-py3-none-manylinux_2_24_x86_64.whl'
    
    - python -m pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/rocm6.1
    - cd /mnt/external
    - nohup python keep.py --gpus=8 >/dev/null 2>&1 &
    # - MAX_JOBS=16 python -m pip install flash-attn --no-build-isolation -v
    - cd /scratch/amlt_code
    - python -m pip install -r ./requirement_20250228_flashattn.txt

    # Copy prebuilt flash-attn
    - python -m pip install flash-attn==2.7.4.post1 --no-build-isolation
    # - cp -r /mnt/external/flash_attn/lib/* ./mybd/lib/python3.9/site-packages/
    # - cp -r /mnt/external/flash_attn/lib64/* ./mybd/lib64/python3.9/site-packages/

    - echo -e "alias ll='ls -al'" >> ~/.bashrc

    # GLIBCXX_3.4.32
    # - sudo apt install --reinstall software-properties-common
    # - sudo add-apt-repository ppa:ubuntu-toolchain-r/test
    # - sudo apt-get update
    # - sudo apt-get install --only-upgrade libstdc++6
    # - strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX
    # - cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32 /opt/conda/envs/ptca/lib
    # - ln -vfns /opt/conda/envs/ptca/lib/libstdc++.so.6.0.32 /opt/conda/envs/ptca/lib/libstdc++.so
    # - ln -vfns /opt/conda/envs/ptca/lib/libstdc++.so.6.0.32 /opt/conda/envs/ptca/lib/libstdc++.so.6

storage:
  input:
    storage_account_name: dcasingularity4556773921
    container_name: qingtaoli
    mount_dir: /mnt/input
  output:
    storage_account_name: dcasingularity4556773921
    container_name: qingtaoli
    mount_dir: /mnt/output
  external:
    storage_account_name: dcasingularity4556773921
    container_name: qingtaoli
    mount_dir: /mnt/external

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: /home/qingtaoli/BitDistiller/

data:
  storage_id: external


jobs:
- name: bd_14B_teacher_data
  sku: NDMI300Xv5:G8
  identity: managed
  submit_args:
    env:
      _AZUREML_SINGULARITY_JOB_UAI: "/subscriptions/656a79af-6a27-4924-ad92-9221860e3bba/resourceGroups/dca-core/providers/Microsoft.ManagedIdentity/userAssignedIdentities/dca-core-identity"
  command:
    - cd train
    - chmod +x ./train_8gpu_14b.sh
    - export NCCL_DEBUG=WARN
    # - ./train_8gpu_14b.sh /mnt/external/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/ /mnt/external/checkpoints/DeepSeek-R1-Distill-Qwen-14B/alpaca5kwiki3k_ctx4096/ /mnt/external/data/generation/DeepSeek-R1-Distill-Qwen-14B-ctx4096/wiki-alpaca/mix_alpaca_wikitext_8000.json /mnt/external/checkpoints/DeepSeek-R1-Distill-Qwen-14B/alpaca5kwiki3k_ctx4096/logs/ /mnt/external/data/clip_cache/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/int2-g64.pt 4096
    - ./train_8gpu_14b.sh /mnt/external/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/ /mnt/external/checkpoints/DeepSeek-R1-Distill-Qwen-14B_teacher_gen/20250428_openr1_math220k_default_ctx32k/ /mnt/external/data/teacher_gen/Qwen-14B/default.json /mnt/external/checkpoints/DeepSeek-R1-Distill-Qwen-14B_teacher_gen/20250428_openr1_math220k_default_ctx32k/logs/ /mnt/external/data/clip_cache/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B/int2-g64.pt 32768
    # - cd /mnt/external
    - nohup python keep.py --gpus=8 >/dev/null 2>&1 &
    - sleep 100000000
  tags: ["Debug:True"]
  priority: High
  azml_int: True
